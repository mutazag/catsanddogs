{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slVkfZECGYuE"
      },
      "source": [
        "# Run Training on Azure ML Compute Instance\n",
        "\n",
        "In this exercise, we will run a deep learning training job on Azure ML Compute Instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEKwxPVBF4Kd"
      },
      "source": [
        "# Predicting cats versus dogs (binary classification)\n",
        "\n",
        "## Dataset \n",
        "\n",
        "The original dataset is avalaible here: [cats and dogs](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip)\n",
        "\n",
        "Run the [downlload bash script](01_download_files.sh) to download the publich cats and dogs dataset and uploaded to a storage account. \n",
        "\n",
        "Run [Explore Dataset Notebook](02_explore_dataset.ipynb) to mount datstore to compute instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1uxFpFNZgj-"
      },
      "source": [
        "## Training Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8rlRtw82Ca2W"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Placeholder for student's code (3 lines of code)\n",
        "# Task: import tensorflow and download the dataset locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enable MLflow tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/04/25 05:33:14 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "mlflow.set_experiment('cats-and-dogs')\n",
        "mlflow.autolog()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data need to be present on the compute instance, or development machine. Refer to [explore data set notebook](02_explore_dataset.ipynb) for details on how to mount a registered `Dataset`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "b4YDJ6ztCa2a",
        "outputId": "608674dd-c921-4f9b-dd93-a69944a61d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['train', 'validation', 'vectorize.py']\n"
          ]
        }
      ],
      "source": [
        "zip_dir = '/mnt/tmp/cats_dogs'\n",
        "import pathlib\n",
        "parent_dir = pathlib.Path(zip_dir)\n",
        "\n",
        "import os \n",
        "print(os.listdir(zip_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FONBvEU5Ca2m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/tmp/cats_dogs/train\n",
            "/mnt/tmp/cats_dogs/validation\n"
          ]
        }
      ],
      "source": [
        "# Create 2 variable called train_dir and test_dir that will contain the path to the 'train' and 'validation' folders\n",
        "train_dir = parent_dir / 'train'\n",
        "test_dir = parent_dir / 'validation'\n",
        "\n",
        "print(train_dir)\n",
        "print(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TfftHwNCa2o"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yeS9IGMJCa2r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "{'cats': 0, 'dogs': 1}\n",
            "(100, 100, 3)\n"
          ]
        }
      ],
      "source": [
        "# Import ImageDataGenerator and create an image generator for the training set\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_img_gen = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    rotation_range=40, \n",
        "    width_shift_range=0.1, \n",
        "    height_shift_range=0.1, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2, \n",
        "    horizontal_flip=True, \n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "# create an image generator for the testing set\n",
        "test_img_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# batch size for the data generators.\n",
        "batch_size=20\n",
        "\n",
        "# define our data generator by specifying its input stream\n",
        "train_data_gen = train_img_gen.flow_from_directory(\n",
        "    batch_size=batch_size, \n",
        "    directory=train_dir, \n",
        "    target_size=(100, 100), \n",
        "    class_mode='binary')\n",
        "\n",
        "test_data_gen = test_img_gen.flow_from_directory(\n",
        "    batch_size=batch_size, \n",
        "    directory=test_dir, \n",
        "    target_size=(100, 100), \n",
        "    class_mode='binary')\n",
        "\n",
        "\n",
        "print(test_data_gen.class_indices)\n",
        "\n",
        "total_train = 2000\n",
        "total_val = 1000\n",
        "\n",
        "print(test_data_gen.image_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdpudNYVCa3F"
      },
      "source": [
        "### Defining the Architecture of CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YfedH9JyCa3G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base model summary\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 7,079,424\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# import VGG16\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "# instantiate a model \n",
        "input_shape = (100, 100, 3)\n",
        "base_model = VGG16(input_shape=input_shape, weights='imagenet', include_top=False)\n",
        "\n",
        "# freeze layers of the base model\n",
        "frozen_layers = 15\n",
        "for layer in base_model.layers[:frozen_layers]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "print('base model summary')\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4hpPlSMiCa4D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tuned model summary\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 500)               2304500   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,019,689\n",
            "Trainable params: 9,384,425\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# add 2 fully connected layers to this VGG16 model\n",
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "tuned_model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(500, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# instantiate and Adam opetimizer with learning rate of .00001\n",
        "optimizer = tf.keras.optimizers.Adam(0.00001)\n",
        "\n",
        "\n",
        "# compile the model and specify loss function \n",
        "tuned_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "print('tuned model summary')\n",
        "tuned_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7aycMPUCa3j"
      },
      "source": [
        "### Training and Evaluation of the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Wp0SBCCGfAu7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/data/model_checkpoint/vgg_checkpoint\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# early stopping if model doesnot improve in 5 epochs \n",
        "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "# decrease the learning rate by a factor of 0.2 if the model doesn't improve after 3 epochs\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0000001)\n",
        "\n",
        "# Model checkpoint location \n",
        "checkpoint_filepath = os.path.expanduser('~/cloudfiles/data/model_checkpoint/vgg_checkpoint')\n",
        "print(checkpoint_filepath)\n",
        "\n",
        "# save bes model weights during learning process\n",
        "model_checkpoint_cb = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz9iyXr5Ca3m",
        "outputId": "8bba06ac-7a3a-403c-a57d-eeb222ad7d92",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-a9e64beea693>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = tuned_model.fit_generator(\n",
            "2022/04/25 05:33:17 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '790f7fd1-abff-4b4f-9e10-8b93dc4828ab', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 83s 813ms/step - loss: 0.5559 - accuracy: 0.7100 - val_loss: 0.4073 - val_accuracy: 0.8070 - lr: 1.0000e-05\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 61s 609ms/step - loss: 0.4097 - accuracy: 0.8080 - val_loss: 0.3161 - val_accuracy: 0.8580 - lr: 1.0000e-05\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 62s 621ms/step - loss: 0.3539 - accuracy: 0.8365 - val_loss: 0.2981 - val_accuracy: 0.8690 - lr: 1.0000e-05\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 65s 650ms/step - loss: 0.3095 - accuracy: 0.8665 - val_loss: 0.3142 - val_accuracy: 0.8660 - lr: 1.0000e-05\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 61s 616ms/step - loss: 0.2933 - accuracy: 0.8655 - val_loss: 0.2838 - val_accuracy: 0.8820 - lr: 1.0000e-05\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 72s 720ms/step - loss: 0.2889 - accuracy: 0.8780 - val_loss: 0.2836 - val_accuracy: 0.8790 - lr: 1.0000e-05\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 65s 651ms/step - loss: 0.2778 - accuracy: 0.8765 - val_loss: 0.2704 - val_accuracy: 0.8730 - lr: 1.0000e-05\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 69s 692ms/step - loss: 0.2644 - accuracy: 0.8875 - val_loss: 0.2612 - val_accuracy: 0.8840 - lr: 1.0000e-05\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 65s 650ms/step - loss: 0.2285 - accuracy: 0.9060 - val_loss: 0.2556 - val_accuracy: 0.8910 - lr: 1.0000e-05\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 65s 650ms/step - loss: 0.2120 - accuracy: 0.9140 - val_loss: 0.2763 - val_accuracy: 0.8920 - lr: 1.0000e-05\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 62s 621ms/step - loss: 0.2079 - accuracy: 0.9245 - val_loss: 0.2570 - val_accuracy: 0.8970 - lr: 1.0000e-05\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 63s 628ms/step - loss: 0.1983 - accuracy: 0.9165 - val_loss: 0.2423 - val_accuracy: 0.9020 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 69s 687ms/step - loss: 0.2028 - accuracy: 0.9210 - val_loss: 0.2352 - val_accuracy: 0.9080 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 62s 622ms/step - loss: 0.1888 - accuracy: 0.9260 - val_loss: 0.2418 - val_accuracy: 0.9060 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 66s 664ms/step - loss: 0.1790 - accuracy: 0.9310 - val_loss: 0.3018 - val_accuracy: 0.8930 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 64s 642ms/step - loss: 0.1657 - accuracy: 0.9365 - val_loss: 0.3291 - val_accuracy: 0.8870 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 62s 618ms/step - loss: 0.1489 - accuracy: 0.9415 - val_loss: 0.2629 - val_accuracy: 0.9020 - lr: 2.0000e-06\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 63s 631ms/step - loss: 0.1464 - accuracy: 0.9450 - val_loss: 0.2645 - val_accuracy: 0.9040 - lr: 2.0000e-06\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 66s 661ms/step - loss: 0.1390 - accuracy: 0.9510 - val_loss: 0.2312 - val_accuracy: 0.9020 - lr: 2.0000e-06\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 61s 614ms/step - loss: 0.1247 - accuracy: 0.9540 - val_loss: 0.3027 - val_accuracy: 0.8950 - lr: 2.0000e-06\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 66s 658ms/step - loss: 0.1328 - accuracy: 0.9475 - val_loss: 0.2449 - val_accuracy: 0.9000 - lr: 2.0000e-06\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 62s 618ms/step - loss: 0.1348 - accuracy: 0.9540 - val_loss: 0.2816 - val_accuracy: 0.8980 - lr: 2.0000e-06\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 62s 621ms/step - loss: 0.1352 - accuracy: 0.9515 - val_loss: 0.2524 - val_accuracy: 0.9010 - lr: 4.0000e-07\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 61s 612ms/step - loss: 0.1244 - accuracy: 0.9580 - val_loss: 0.2479 - val_accuracy: 0.9030 - lr: 4.0000e-07\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 62s 622ms/step - loss: 0.1212 - accuracy: 0.9565 - val_loss: 0.2436 - val_accuracy: 0.9040 - lr: 4.0000e-07\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 62s 621ms/step - loss: 0.1216 - accuracy: 0.9540 - val_loss: 0.2477 - val_accuracy: 0.9030 - lr: 1.0000e-07\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 63s 629ms/step - loss: 0.1182 - accuracy: 0.9570 - val_loss: 0.2480 - val_accuracy: 0.9030 - lr: 1.0000e-07\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 63s 629ms/step - loss: 0.1379 - accuracy: 0.9450 - val_loss: 0.2451 - val_accuracy: 0.9040 - lr: 1.0000e-07\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 63s 630ms/step - loss: 0.1385 - accuracy: 0.9515 - val_loss: 0.2468 - val_accuracy: 0.9030 - lr: 1.0000e-07\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 63s 627ms/step - loss: 0.1219 - accuracy: 0.9540 - val_loss: 0.2432 - val_accuracy: 0.9030 - lr: 1.0000e-07\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 61s 611ms/step - loss: 0.1307 - accuracy: 0.9520 - val_loss: 0.2470 - val_accuracy: 0.9040 - lr: 1.0000e-07\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 62s 619ms/step - loss: 0.1154 - accuracy: 0.9590 - val_loss: 0.2478 - val_accuracy: 0.9020 - lr: 1.0000e-07\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 61s 615ms/step - loss: 0.1313 - accuracy: 0.9590 - val_loss: 0.2497 - val_accuracy: 0.9010 - lr: 1.0000e-07\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 65s 648ms/step - loss: 0.1270 - accuracy: 0.9535 - val_loss: 0.2496 - val_accuracy: 0.9010 - lr: 1.0000e-07\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 62s 619ms/step - loss: 0.1190 - accuracy: 0.9625 - val_loss: 0.2532 - val_accuracy: 0.9010 - lr: 1.0000e-07\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 65s 653ms/step - loss: 0.1388 - accuracy: 0.9445 - val_loss: 0.2500 - val_accuracy: 0.9000 - lr: 1.0000e-07\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 64s 636ms/step - loss: 0.1254 - accuracy: 0.9565 - val_loss: 0.2520 - val_accuracy: 0.9000 - lr: 1.0000e-07\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp_xzmc_v_/model/data/model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/04/25 06:13:22 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp_xzmc_v_/model, flavor: keras), fall back to return ['tensorflow==2.8.0', 'keras==2.8.0']. Set logging level to DEBUG to see the full traceback.\n"
          ]
        }
      ],
      "source": [
        "# Train for 50 epochs (unless stopped early by callback functions)\n",
        "history = tuned_model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=50,\n",
        "    validation_data=test_data_gen,\n",
        "    validation_steps=total_val // batch_size,\n",
        "    callbacks=[early_stop_cb, reduce_lr, model_checkpoint_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4CgxmxeCa3q"
      },
      "source": [
        "## Analysing the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ygPgB2hqCa3s",
        "outputId": "297d778a-ff92-4790-c496-d7f35afad562"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the accuracy for the training and validation set\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='training')\n",
        "plt.plot(history.history['val_accuracy'], label='validation')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DL_Lab4_Exercise2_Solutions.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('azureml_py38_PT_TF')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
